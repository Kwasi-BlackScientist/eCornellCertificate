{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "## Get Started\n",
       "\n",
       "<p>Let's import a few packages that you will need. You will work with the <a href=\"https://archive.ics.uci.edu/ml/datasets/Ionosphere\">ION</a> dataset for this project.</p> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "## Get Started\n",
    "\n",
    "<p>Let's import a few packages that you will need. You will work with the <a href=\"https://archive.ics.uci.edu/ml/datasets/Ionosphere\">ION</a> dataset for this project.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pylab import *\n",
    "from numpy.matlib import repmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "from helper import *\n",
    "\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ion.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ion.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-157cdcc824af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ion.mat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mxTr\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'xTr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0myTr\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'yTr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mxTe\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'xTe'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0myTe\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'yTe'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \"\"\"\n\u001b[0;32m    215\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ion.mat'"
     ]
    }
   ],
   "source": [
    "data = loadmat(\"ion.mat\")\n",
    "xTr  = data['xTr'].T\n",
    "yTr  = data['yTr'].flatten()\n",
    "xTe  = data['xTe'].T\n",
    "yTe  = data['yTe'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regression tree with no restriction on its depth. \n",
    "# This is equivalent to what you implemented in the previous project\n",
    "# if you want to create a tree of max depth k\n",
    "# then call h.RegressionTree(depth=k)\n",
    "tree = RegressionTree(depth=np.inf)\n",
    "\n",
    "# To fit/train the regression tree\n",
    "tree.fit(xTr, yTr)\n",
    "\n",
    "# To use the trained regression tree to make prediction\n",
    "pred = tree.predict(xTr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-a0eb7084ff46>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-a0eb7084ff46>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    We have also created a square loss function that takes in the prediction <code>pred</code> and ground truth <code>truth</code> and returns the average square loss between prediction and ground truth.\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "We have also created a square loss function that takes in the prediction <code>pred</code> and ground truth <code>truth</code> and returns the average square loss between prediction and ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(pred, truth):\n",
    "    return np.mean((pred - truth)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, look at the performance of your tree on both the training set and test set using the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Loss: {:.4f}'.format(square_loss(tree.predict(xTr), yTr)))\n",
    "print('Test Loss: {:.4f}'.format(square_loss(tree.predict(xTe), yTe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-542c193e9d17>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-542c193e9d17>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    <p1>As you can see, your tree achives zero training loss on the training set but not zero test loss. Clearly, the model is overfitting! To reduce overfitting, you need to control the depth of the tree. One way to pick the optimal depth is to do kFold Cross Validation. To do so, you will first implement <code>grid_search</code>, which finds the best depths given a training set and validation set. Then you will implement <code>generate_kFold</code>, which generates the split for kFold cross validation. Finally, you will combine the two functions to implement <code>cross_validation</code></p1>.\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Implement Cross Validation\n",
    "%%HTML\n",
    "<p1>As you can see, your tree achives zero training loss on the training set but not zero test loss. Clearly, the model is overfitting! To reduce overfitting, you need to control the depth of the tree. One way to pick the optimal depth is to do kFold Cross Validation. To do so, you will first implement <code>grid_search</code>, which finds the best depths given a training set and validation set. Then you will implement <code>generate_kFold</code>, which generates the split for kFold cross validation. Finally, you will combine the two functions to implement <code>cross_validation</code></p1>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Part One: Implement <code>grid_search</code>[Graded]</h3>\n",
       "\n",
       "Implement the function <code>grid_search</code>, which takes in a training set <code>xTr, yTr</code>, a validation set <code>xVal, yVal</code> and a list of tree depth candidates <code>depths</code>. Your job here is to fit a regression tree for each depth candidate on the training set <code>xTr, yTr</code>, evaluate the fitted tree on the validation set <code>xVal, yVal</code> and then pick the candidate that yields the lowest loss for the validation set. Note: in the event of a tie, return the smallest depth candidate.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3>Part One: Implement <code>grid_search</code>[Graded]</h3>\n",
    "\n",
    "Implement the function <code>grid_search</code>, which takes in a training set <code>xTr, yTr</code>, a validation set <code>xVal, yVal</code> and a list of tree depth candidates <code>depths</code>. Your job here is to fit a regression tree for each depth candidate on the training set <code>xTr, yTr</code>, evaluate the fitted tree on the validation set <code>xVal, yVal</code> and then pick the candidate that yields the lowest loss for the validation set. Note: in the event of a tie, return the smallest depth candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(xTr, yTr, xVal, yVal, depths):\n",
    "    '''\n",
    "    Input:\n",
    "        xTr: nxd matrix\n",
    "        yTr: n vector\n",
    "        xVal: mxd matrix\n",
    "        yVal: m vector\n",
    "        depths: a list of len k\n",
    "    Return:\n",
    "        best_depth: the depth that yields that lowest loss on the validation set\n",
    "        training losses: a list of len k. the i-th entry corresponds to the the training loss\n",
    "                the tree of depths[i]\n",
    "        validation_losses: a list of len k. the i-th entry corresponds to the the validation loss\n",
    "                the tree of depths[i]\n",
    "    '''\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    best_depth = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in depths:\n",
    "        treeGrid = RegressionTree(depth=i)\n",
    "        treeGrid.fit(xTr,yTr)\n",
    "        predTr = treeGrid.predict(xTr)\n",
    "        predVal= treeGrid.predict(xVal)\n",
    "        training_losses.append(square_loss(predTr,yTr)) #square_loss(predTr,yTr)\n",
    "        validation_losses.append(square_loss(predVal,yVal))\n",
    "    \n",
    "    #print('yTr: ', yTr.shape)\n",
    "    \n",
    "    #print('traininglossmin: ', training_losses.index(min(training_losses)))\n",
    "    #print('validationlossmin: ', validation_losses.index(min(validation_losses)))\n",
    "    #print('fit: ', fit)\n",
    "    \n",
    "    best_depth = depths[validation_losses.index(min(validation_losses))]\n",
    "    \n",
    "    #print('best: ', best_depth)\n",
    "    return best_depth, training_losses, validation_losses\n",
    "\n",
    "#depths = [1,2,3,4,5]\n",
    "#k = len(depths)\n",
    "#best_depth, training_losses, validation_losses = grid_search(xTr, yTr, xTe, yTe, depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following tests check that your implementation of grid search returns the correct number of training and validation loss values and the correct best depth\n",
    "\n",
    "depths = [1,2,3,4,5]\n",
    "k = len(depths)\n",
    "best_depth, training_losses, validation_losses = grid_search(xTr, yTr, xTe, yTe, depths)\n",
    "best_depth_grader, training_losses_grader, validation_losses_grader = grid_search_grader(xTr, yTr, xTe, yTe, depths)\n",
    "\n",
    "# Check the length of the training loss\n",
    "def grid_search_test1():\n",
    "    return (len(training_losses) == k) \n",
    "\n",
    "# Check the length of the validation loss\n",
    "def grid_search_test2():\n",
    "    return (len(validation_losses) == k)\n",
    "\n",
    "# Check the argmin\n",
    "def grid_search_test3():\n",
    "    return (best_depth == depths[np.argmin(validation_losses)])\n",
    "\n",
    "def grid_search_test4():\n",
    "    return (best_depth == best_depth_grader)\n",
    "\n",
    "def grid_search_test5():\n",
    "    return np.linalg.norm(np.array(training_losses) - np.array(training_losses_grader)) < 1e-7\n",
    "\n",
    "def grid_search_test6():\n",
    "    return np.linalg.norm(np.array(validation_losses) - np.array(validation_losses_grader)) < 1e-7\n",
    "\n",
    "runtest(grid_search_test1, 'grid_search_test1')\n",
    "runtest(grid_search_test2, 'grid_search_test2')\n",
    "runtest(grid_search_test3, 'grid_search_test3')\n",
    "runtest(grid_search_test4, 'grid_search_test4')\n",
    "runtest(grid_search_test5, 'grid_search_test5')\n",
    "runtest(grid_search_test6, 'grid_search_test6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Part Two: Implement <code>generate_kFold</code>[Graded]</h3>\n",
       "\n",
       "Now, implement the <code>generate_kFold</code> function, which takes in the number of training examples <code>n</code> and the number of folds <code>k</code> and returns a list of <code>k</code> folds where each fold takes the form <code>(training indices, validation indices)</code>.\n",
       "\n",
       "For instance, if n = 3 and k = 3, then we have three indices <code>[0,1,2]</code> and we are trying to split it k=3 times to obtain different training/validation splits. \n",
       "One possible output of the the function is <code>[([0, 1], [2]), ([1, 2], [0]), ([0, 2], [1])]</code> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3>Part Two: Implement <code>generate_kFold</code>[Graded]</h3>\n",
    "\n",
    "Now, implement the <code>generate_kFold</code> function, which takes in the number of training examples <code>n</code> and the number of folds <code>k</code> and returns a list of <code>k</code> folds where each fold takes the form <code>(training indices, validation indices)</code>.\n",
    "\n",
    "For instance, if n = 3 and k = 3, then we have three indices <code>[0,1,2]</code> and we are trying to split it k=3 times to obtain different training/validation splits. \n",
    "One possible output of the the function is <code>[([0, 1], [2]), ([1, 2], [0]), ([0, 2], [1])]</code> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kFold(n, k):\n",
    "    '''\n",
    "    Input:\n",
    "        n: number of training examples\n",
    "        k: number of folds\n",
    "    Returns:\n",
    "        kfold_indices: a list of len k. Each entry takes the form\n",
    "        (training indices, validation indices)\n",
    "    '''\n",
    "    assert k >= 2\n",
    "    kfold_indices = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in range(k):\n",
    "        instances = np.arange(n)\n",
    "        data= np.random.permutation(instances)\n",
    "        kfold_indices.append((data[int((n/k)):],data[:int((n/k))]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    t = [((len(train_indices) , len(test_indices))) \n",
    "        for (train_indices, test_indices) in kfold_indices]\n",
    "\n",
    "    ratio_test = []\n",
    "    for (train_indices, validation_indices) in kfold_indices:\n",
    "        ratio = len(validation_indices) / len(train_indices)\n",
    "        #print('ratio: ', ratio)\n",
    "        ratio_test.append((ratio > 0.24 and ratio < 0.26))\n",
    "    \n",
    "    train_indices_set = set() # to keep track of training indices for each fold\n",
    "    validation_indices_set = set() # to keep track of validation indices for each fold\n",
    "    for (train_indices, validation_indices) in kfold_indices:\n",
    "        train_indices_set = train_indices_set.union(set(train_indices))\n",
    "        validation_indices_set = validation_indices_set.union(set(validation_indices))\n",
    "        \n",
    "        \n",
    "    #print('train_indices_set: ', train_indices_set)\n",
    "    #print('val_idnices_set:' , validation_indices_set)\n",
    "    #print('ratio_test: ', ratio_test)\n",
    "    #print(\"t: \", t)\n",
    "    #print('lenTrain: ', len(train_indices))\n",
    "    #print('kfolds: ', kfold_indices[0])\n",
    "    \n",
    "    #assert train_indices_set == set(np.arange(1004)) \n",
    "    #assert validation_indices_set == set(np.arange(1004))\n",
    "    #return None\n",
    "    return kfold_indices\n",
    "\n",
    "#generate_kFold(1004,5)\n",
    "#runtest(generate_kFold_test2, 'generate_kFold_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following tests check that your generate_kFold function \n",
    "# returns the correct number of total indices, \n",
    "# train and test indices, and the correct ratio\n",
    "\n",
    "kfold_indices = generate_kFold(1004, 5)\n",
    "\n",
    "def generate_kFold_test1():\n",
    "    return len(kfold_indices) == 5 # you should gener   ate 5 folds\n",
    "\n",
    "def generate_kFold_test2():\n",
    "    t = [((len(train_indices) + len(test_indices)) == 1004) \n",
    "         for (train_indices, test_indices) in kfold_indices]\n",
    "    return np.all(t) # make sure that both for each fold, the number of examples sum up to 1004\n",
    "\n",
    "def generate_kFold_test3():\n",
    "    ratio_test = []\n",
    "    for (train_indices, validation_indices) in kfold_indices:\n",
    "        ratio = len(validation_indices) / len(train_indices)\n",
    "        ratio_test.append((ratio > 0.24 and ratio < 0.26))\n",
    "    # make sure that both for each fold, the training to validation \n",
    "    # examples ratio is in between 0.24 and 0.25\n",
    "    return np.all(ratio_test) \n",
    "\n",
    "def generate_kFold_test4():\n",
    "    train_indices_set = set() # to keep track of training indices for each fold\n",
    "    validation_indices_set = set() # to keep track of validation indices for each fold\n",
    "    for (train_indices, validation_indices) in kfold_indices:\n",
    "        train_indices_set = train_indices_set.union(set(train_indices))\n",
    "        validation_indices_set = validation_indices_set.union(set(validation_indices))\n",
    "    \n",
    "    # Make sure that you use all the examples in all the training fold and validation fold\n",
    "    return train_indices_set == set(np.arange(1004)) and validation_indices_set == set(np.arange(1004))\n",
    "\n",
    "\n",
    "runtest(generate_kFold_test1, 'generate_kFold_test1')\n",
    "runtest(generate_kFold_test2, 'generate_kFold_test2')\n",
    "runtest(generate_kFold_test3, 'generate_kFold_test3')\n",
    "runtest(generate_kFold_test4, 'generate_kFold_test4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h3>Part Three: Implement <code>cross_validation</code>[Graded]</h3>\n",
       "\n",
       "Use <code>grid_search</code> to implement the <code>cross_validation</code> function that takes in the training set <code>xTr, yTr</code>, a list of depth candidates <code>depths</code> and performs K-fold cross validation on the training set. We use <code>generate_kFold</code> to generate the K training/validation split. Using <code>indices</code>, the function will do a grid search  on each fold and return the parameter that yields the best average validation loss across the folds. Note that in event of tie, the function should return the smallest depth candidate.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<h3>Part Three: Implement <code>cross_validation</code>[Graded]</h3>\n",
    "\n",
    "Use <code>grid_search</code> to implement the <code>cross_validation</code> function that takes in the training set <code>xTr, yTr</code>, a list of depth candidates <code>depths</code> and performs K-fold cross validation on the training set. We use <code>generate_kFold</code> to generate the K training/validation split. Using <code>indices</code>, the function will do a grid search  on each fold and return the parameter that yields the best average validation loss across the folds. Note that in event of tie, the function should return the smallest depth candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(xTr, yTr, depths, indices):\n",
    "    '''\n",
    "    Input:\n",
    "        xTr: nxd matrix (training data)\n",
    "        yTr: n vector (training data)\n",
    "        depths: a list (of length l) depths to be tried out\n",
    "        indices: indices from generate_kFold\n",
    "    Returns:\n",
    "        best_depth: the best parameter \n",
    "        training losses: a list of lenth l. the i-th entry corresponds to the the average training loss\n",
    "                the tree of depths[i]\n",
    "        validation_losses: a list of length l. the i-th entry corresponds to the the average validation loss\n",
    "                the tree of depths[i] \n",
    "    '''\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    best_depth = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    '''\n",
    "    for i in range(k):\n",
    "        \n",
    "    \n",
    "        xValList = [xTr[i] for i in indices[i-1][0]]\n",
    "        yValList = [yTr[i] for i in indices[i-1][0]]\n",
    "        xVal = np.asarray(xValList)\n",
    "        yVal = np.asarray(yValList)\n",
    "        #yVal = yTr[indices[1]]\n",
    "    \n",
    "    \n",
    "        best_depth, training_losses, validation_losses = grid_search(xTr, yTr,xVal, yVal, depths)\n",
    "    \n",
    "    #print('len xVal: ', len(xVal))\n",
    "    #print('len yVal: ', len(yVal))\n",
    "    #use the values of the indices to create your validation and training data set splits. Then pass them to the grid_search function\n",
    "    \n",
    "    #print('indices: ', len(indices[0][1]))\n",
    "    #print('xVal: ', xValList)\n",
    "    #print('yVal: ', yVal)\n",
    "    print('best_depth:', best_depth)\n",
    "    print('best_grader:' , best_depth_grader)\n",
    "    print('training_losses', training_losses)\n",
    "    print('training_grader: ', training_losses_grader)\n",
    "    \n",
    "    \n",
    "    #return None\n",
    "    '''\n",
    "    \n",
    "    for i,j in indices:\n",
    "        xtrain, ytrain = xTr[i], yTr[i]\n",
    "        xVal, yVal = xTr[j], yTr[j]\n",
    "    \n",
    "        #xValList = [xTr[i] for i in indices[i-1][0]]\n",
    "        #yValList = [yTr[i] for i in indices[i-1][0]]\n",
    "        #xVal = np.asarray(xValList)\n",
    "        #yVal = np.asarray(yValList)\n",
    "        #yVal = yTr[indices[1]]\n",
    "    \n",
    "    \n",
    "        best_depth, training_losses, validation_losses = grid_search(xtrain, ytrain,xVal, yVal, depths)\n",
    "    \n",
    "        #print('len xVal: ', len(xVal))\n",
    "        #print('len yVal: ', len(yVal))\n",
    "        #use the values of the indices to create your validation and training data set splits. Then pass them to the grid_search function\n",
    "    \n",
    "        #print('indices: ', len(indices[0][1]))\n",
    "        #print('xVal: ', xValList)\n",
    "        #print('yVal: ', yVal)\n",
    "        print('best_depth:', best_depth)\n",
    "        print('best_grader:' , best_depth_grader)\n",
    "        print('training_losses', training_losses)\n",
    "        print('training_grader: ', training_losses_grader)\n",
    "    \n",
    "    #training_losses = np.mean(training_losses)\n",
    "    #validation_losses = np.mean(validation_losses)\n",
    "    \n",
    "    training_losses = np.mean(training_losses, axis=0)\n",
    "    validation_losses = np.mean(validation_losses, axis=0)\n",
    "    best_depth = depths[np.argmin(validation_losses)]\n",
    "    \n",
    "    #return None\n",
    "    \n",
    "    return best_depth, training_losses, validation_losses\n",
    "\n",
    "#depths = [1,2,3,4]\n",
    "#k = len(depths)\n",
    "\n",
    "# generate indices\n",
    "# the same indices will be used to cross check your solution and ours\n",
    "#indices = generate_kFold(len(xTr), 5)\n",
    "#best_depth, training_losses, validation_losses = cross_validation(xTr, yTr, depths, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following tests check that your implementation of cross_validation returns the correct number of training and validation losses, the correct \"best depth\" and the correct values for training and validation loss\n",
    "\n",
    "depths = [1,2,3,4]\n",
    "k = len(depths)\n",
    "\n",
    "# generate indices\n",
    "# the same indices will be used to cross check your solution and ours\n",
    "indices = generate_kFold(len(xTr), 5)\n",
    "best_depth, training_losses, validation_losses = cross_validation(xTr, yTr, depths, indices)\n",
    "best_depth_grader, training_losses_grader, validation_losses_grader = cross_validation_grader(xTr, yTr, depths, indices)\n",
    "\n",
    "# Check the length of the training loss\n",
    "def cross_validation_test1():\n",
    "    return (len(training_losses) == k) \n",
    "\n",
    "# Check the length of the validation loss\n",
    "def cross_validation_test2():\n",
    "    return (len(validation_losses) == k)\n",
    "\n",
    "# Check the argmin\n",
    "def cross_validation_test3():\n",
    "    return (best_depth == depths[np.argmin(validation_losses)])\n",
    "\n",
    "def cross_validation_test4():\n",
    "    return (best_depth == best_depth_grader)\n",
    "\n",
    "def cross_validation_test5():\n",
    "    return np.linalg.norm(np.array(training_losses) - np.array(training_losses_grader)) < 1e-7\n",
    "\n",
    "def cross_validation_test6():\n",
    "    return np.linalg.norm(np.array(validation_losses) - np.array(validation_losses_grader)) < 1e-7\n",
    "\n",
    "runtest(cross_validation_test1, 'cross_validation_test1')\n",
    "runtest(cross_validation_test2, 'cross_validation_test2')\n",
    "runtest(cross_validation_test3, 'cross_validation_test3')\n",
    "runtest(cross_validation_test4, 'cross_validation_test4')\n",
    "runtest(cross_validation_test5, 'cross_validation_test5')\n",
    "runtest(cross_validation_test6, 'cross_validation_test6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
