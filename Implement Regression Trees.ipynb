{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Implementing CART</h2>\n",
       "\n",
       "### Getting Started\n",
       "\n",
       "Before you get started, let's import a few packages that you will need. In addition, you will load two binary classification dataset - the spiral dataset and the <a href=\"https://archive.ics.uci.edu/ml/datasets/Ionosphere\">ION</a> dataset. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h2>Implementing CART</h2>\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "Before you get started, let's import a few packages that you will need. In addition, you will load two binary classification dataset - the spiral dataset and the <a href=\"https://archive.ics.uci.edu/ml/datasets/Ionosphere\">ION</a> dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Implementing CART</h2>\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "Before you get started, let's import a few packages that you will need. In addition, you will load two binary classification dataset - the spiral dataset and the <a href=\"https://archive.ics.uci.edu/ml/datasets/Ionosphere\">ION</a> dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spiraldata(N=300):\n",
    "    r = np.linspace(1,2*np.pi,N) # generate a vector of \"radius\" values\n",
    "    xTr1 = np.array([np.sin(2.*r)*r, np.cos(2*r)*r]).T # generate a curve that draws circles with increasing radius\n",
    "    xTr2 = np.array([np.sin(2.*r+np.pi)*r, np.cos(2*r+np.pi)*r]).T\n",
    "    xTr = np.concatenate([xTr1, xTr2], axis=0)\n",
    "    yTr = np.concatenate([np.ones(N), -1 * np.ones(N)])\n",
    "    xTr = xTr + np.random.randn(xTr.shape[0], xTr.shape[1])*0.2\n",
    "    \n",
    "    # Now sample alternating values to generate the test and train sets.\n",
    "    xTe = xTr[::2,:]\n",
    "    yTe = yTr[::2]\n",
    "    xTr = xTr[1::2,:]\n",
    "    yTr = yTr[1::2]\n",
    "    \n",
    "    return xTr, yTr, xTe, yTe\n",
    "\n",
    "xTrSpiral, yTrSpiral, xTeSpiral, yTeSpiral = spiraldata(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can plot xTrSpiral to see the curve generated by the function above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xTrSpiral[:,0], xTrSpiral[:,1],30,yTrSpiral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The following code loads the ION dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in some binary test data (labels are -1, +1)\n",
    "data = loadmat(\"ion.mat\")\n",
    "\n",
    "# Load the training data\n",
    "xTrIon  = data['xTr'].T\n",
    "yTrIon  = data['yTr'].flatten()\n",
    "\n",
    "# Load the test data\n",
    "xTeIon  = data['xTe'].T\n",
    "yTeIon  = data['yTe'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2> Implement Regression Trees </h2>\n",
       "\n",
       "\n",
       "<h3> Part One: Implement <code>sqimpurity</code> [Graded]</h3>\n",
       "\n",
       "<p>First, implement the function <code>sqimpurity</code> which takes as input a vector of $n$ labels and outputs the corresponding squared loss impurity\n",
       "    $$\\sum_{i} (y_i-\\bar{y}_i)^2 \\textrm{ where: } \\bar{y}_i=\\frac{1}{n}\\sum_{i} y_i$$\n",
       "</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h2> Implement Regression Trees </h2>\n",
    "\n",
    "\n",
    "<h3> Part One: Implement <code>sqimpurity</code> [Graded]</h3>\n",
    "\n",
    "<p>First, implement the function <code>sqimpurity</code> which takes as input a vector of $n$ labels and outputs the corresponding squared loss impurity\n",
    "    $$\\sum_{i} (y_i-\\bar{y}_i)^2 \\textrm{ where: } \\bar{y}_i=\\frac{1}{n}\\sum_{i} y_i$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqimpurity(yTr):\n",
    "    \"\"\"Computes the weighted variance of the labels\n",
    "    \n",
    "    Input:\n",
    "        yTr:     n-dimensional vector of labels\n",
    "    \n",
    "    Output:\n",
    "        impurity: weighted variance / squared loss impurity of this data set\n",
    "    \"\"\"\n",
    "    \n",
    "    N, = yTr.shape\n",
    "    #print('N: ', N)\n",
    "    assert N > 0 # must have at least one sample\n",
    "    impurity = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #implement y_bar wich is the average label\n",
    "    y_bar = np.sum(yTr)/N\n",
    "    impurity = np.sum((yTr - y_bar)**2)\n",
    "\n",
    "    \n",
    "    \n",
    "    return impurity\n",
    "\n",
    "yTr = np.random.randn(100) # generate random labels\n",
    "impurity = sqimpurity(yTr) # compute impurity\n",
    "impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqimpurity_test1():\n",
    "    yTr = np.random.randn(100) # generate random labels\n",
    "    impurity = sqimpurity(yTr) # compute impurity\n",
    "    return np.isscalar(impurity)  # impurity should be scalar\n",
    "\n",
    "def sqimpurity_test2():\n",
    "    yTr = np.random.randn(100) # generate random labels\n",
    "    impurity = sqimpurity(yTr) # compute impurity\n",
    "    return impurity >= 0 # impurity should be nonnegative\n",
    "\n",
    "def sqimpurity_test3():\n",
    "    yTr = np.ones(100) # generate an all one vector as labels\n",
    "    impurity = sqimpurity(yTr) # compute impurity\n",
    "    return np.isclose(impurity, 0) # impurity should be zero since the labels are homogeneous\n",
    "\n",
    "def sqimpurity_test4():\n",
    "    yTr = np.arange(-5, 6) # generate a vector with mean zero\n",
    "    impurity = sqimpurity(yTr) # compute impurity\n",
    "    sum_of_squares = np.sum(yTr ** 2) \n",
    "    return np.isclose(impurity, sum_of_squares) # with mean zero, then the impurity should be the sum of squares\n",
    "\n",
    "def sqimpurity_test5():\n",
    "    yTr = np.random.randn(100) # generate random labels\n",
    "    impurity = sqimpurity(yTr)\n",
    "    impurity_grader = sqimpurity_grader(yTr)\n",
    "    return np.isclose(impurity, impurity_grader)\n",
    "\n",
    "runtest(sqimpurity_test1, 'sqimpurity_test1')\n",
    "runtest(sqimpurity_test2, 'sqimpurity_test2')\n",
    "runtest(sqimpurity_test3, 'sqimpurity_test3')\n",
    "runtest(sqimpurity_test4, 'sqimpurity_test4')\n",
    "runtest(sqimpurity_test5, 'sqimpurity_test5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Part Two: Implement <code>sqsplit</code> [Graded]</h3>\n",
       "\n",
       "<p>Now implement <code>sqsplit</code>, which takes as input a data set with labels and computes the best feature and cut-value of an optimal split based on the squared error impurity. The <code>sqsplit</code> function takes as input a data set of row vectors and a label vector and outputs a feature dimension, a cut threshold, and the impurity loss of this best split. The cut value should be the average of the values in the dimension where two datapoints are split. To find the best split, evaluate all possible splits and then search for the split that yields the minimum loss.</p> \n",
       "\n",
       "<p>Remember that we evaluate the quality of a split of a parent set $S_P$ into two sets $S_L$ and $S_R$ by the weighted impurity of the two branches, i.e.</p>\n",
       "\n",
       "$\\frac{\\left|S_L\\right|}{\\left|S_P\\right|}I\\left(S_L\\right)+\\frac{\\left|S_R\\right|}{\\left|S_P\\right|}I\\left(S_R\\right)$\n",
       "\n",
       "<p>In the case of the squared loss, this becomes:</p>\n",
       "\n",
       "$\\frac{1}{|S_P|}\\sum_{(x,y)\\in S_L}(y-\\bar{y}_{S_L})^2 +\\frac{1}{|S_P|}\\sum_{(x,y)\\in S_R}(y-\\bar{y}_{S_R})^2$\n",
       "\n",
       "<em>Note: Avoid splitting on datapoints with same value in a dimension.</em> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3> Part Two: Implement <code>sqsplit</code> [Graded]</h3>\n",
    "\n",
    "<p>Now implement <code>sqsplit</code>, which takes as input a data set with labels and computes the best feature and cut-value of an optimal split based on the squared error impurity. The <code>sqsplit</code> function takes as input a data set of row vectors and a label vector and outputs a feature dimension, a cut threshold, and the impurity loss of this best split. The cut value should be the average of the values in the dimension where two datapoints are split. To find the best split, evaluate all possible splits and then search for the split that yields the minimum loss.</p> \n",
    "\n",
    "<p>Remember that we evaluate the quality of a split of a parent set $S_P$ into two sets $S_L$ and $S_R$ by the weighted impurity of the two branches, i.e.</p>\n",
    "\n",
    "$\\frac{\\left|S_L\\right|}{\\left|S_P\\right|}I\\left(S_L\\right)+\\frac{\\left|S_R\\right|}{\\left|S_P\\right|}I\\left(S_R\\right)$\n",
    "\n",
    "<p>In the case of the squared loss, this becomes:</p>\n",
    "\n",
    "$\\frac{1}{|S_P|}\\sum_{(x,y)\\in S_L}(y-\\bar{y}_{S_L})^2 +\\frac{1}{|S_P|}\\sum_{(x,y)\\in S_R}(y-\\bar{y}_{S_R})^2$\n",
    "\n",
    "<em>Note: Avoid splitting on datapoints with same value in a dimension.</em> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqsplit(xTr, yTr):\n",
    "    \"\"\"Finds the best feature, cut value, and loss value.\n",
    "    \n",
    "    Input:\n",
    "        xTr:     n x d matrix of data points\n",
    "        yTr:     n-dimensional vector of labels\n",
    "    \n",
    "    Output:\n",
    "        feature:  index of the best cut's feature\n",
    "        cut:      cut-value of the best cut\n",
    "        bestloss: loss of the best cut\n",
    "    \"\"\"\n",
    "    N,D = xTr.shape\n",
    "    assert D > 0 # must have at least one dimension\n",
    "    assert N > 1 # must have at least two samples\n",
    "    \n",
    "    bestloss = np.inf\n",
    "    feature = np.inf\n",
    "    cut = np.inf\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #xTr = np.argsort(xTr, 0)\n",
    "    for i in range(D):\n",
    "        xTrindex = xTr[:,i].argsort()\n",
    "        yTrsort = yTr[xTrindex] #yTr.argsort()\n",
    "        xTrsort = xTr[xTrindex, i]\n",
    "        #for y in xTrsort:\n",
    "        for y in range(N-1):\n",
    "        #for y in range(xTr.shape[0]):\n",
    "            if xTrsort[y] != xTrsort[y+1]:\n",
    "                #xTrL = xTr[:np.where(xTr[xTrsort,i]==y)[0][0]]\n",
    "                #print('xTrL: ', xTrL)\n",
    "                #xTrR = xTr[np.where(xTr[xTrsort]==y)[0][0]:]\n",
    "                #print('xTrR: ', xTrR)\n",
    "                yTrL = yTrsort[:y+1]   #yTr[:np.where(xTr[xTrsort,i] ==y)[0][0]]\n",
    "               # print('yTrL: ', yTrL)\n",
    "                yTrR = yTrsort[y+1:] #yTr[np.where(xTr[xTrsort,i] ==y)[0][0]:]\n",
    "               # print('yTrR: ', yTrR)\n",
    "   \n",
    "                loss = sqimpurity(yTrL)+sqimpurity(yTrR)\n",
    "                if loss < bestloss:\n",
    "                    bestloss = loss \n",
    "                    cut = (xTrsort[y]+xTrsort[y+1])/2\n",
    "                    feature = i\n",
    "        #N, = yTrL.shape\n",
    "    #print('shape', N)\n",
    "   # print('feature: ', feature)\n",
    "   # print('cut:', cut)\n",
    "   # print('bestloss: ', bestloss)\n",
    "    #return None \n",
    "    \n",
    "    \n",
    "    \n",
    "    return feature, cut, bestloss\n",
    "\n",
    "# x = np.array(range(1000)).reshape(-1,1)\n",
    "# y = np.hstack([np.ones(500),-1*np.ones(500)]).T\n",
    "# _, cut, _ = sqsplit(x, y)\n",
    "# _, cut, _ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tests below check that your sqsplit function returns the correct values for several different input datasets\n",
    "\n",
    "t0 = time.time()\n",
    "fid, cut, loss = sqsplit(xTrIon,yTrIon)\n",
    "t1 = time.time()\n",
    "\n",
    "print('Elapsed time: {:0.2f} seconds'.format(t1-t0))\n",
    "print(\"The best split is on feature 2 on value 0.304\")\n",
    "print(\"Your tree split on feature %i on value: %2.3f \\n\" % (fid,cut))\n",
    "\n",
    "def sqsplit_test1():\n",
    "    a = np.isclose(sqsplit(xor4, yor4)[2] / len(yor4), .25)\n",
    "    b = np.isclose(sqsplit(xor3, yor3)[2] / len(yor3), .25)\n",
    "    c = np.isclose(sqsplit(xor2, yor2)[2] / len(yor2), .25)\n",
    "    return a and b and c\n",
    "\n",
    "def sqsplit_test2():\n",
    "    x = np.array(range(1000)).reshape(-1,1)\n",
    "    y = np.hstack([np.ones(500),-1*np.ones(500)]).T\n",
    "    _, cut, _ = sqsplit(x, y)\n",
    "    return cut <= 500 or cut >= 499\n",
    "\n",
    "def sqsplit_test3():\n",
    "    fid, cut, loss = sqsplit(xor5,yor5)\n",
    "    # cut should be 0.5 but 0 is also accepted\n",
    "    return fid == 0 and (cut >= 0 or cut <= 1) and np.isclose(loss / len(yor5), 2/3)\n",
    "\n",
    "runtest(sqsplit_test1,'sqsplit_test1')\n",
    "runtest(sqsplit_test2,'sqsplit_test2')\n",
    "runtest(sqsplit_test3,'sqsplit_test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Part Three: Implement <code>cart</code> [Graded]</h3>\n",
       "\n",
       "In this section, you will implement the function <code>cart</code>, which returns a regression tree based on the minimum squared loss splitting rule. You should use the function <code>sqsplit</code> to make your splits. <p>Use the provided <code>TreeNode</code> class below to represent your tree. Note that the nature of CART trees implies that every node has exactly 0 or 2 children.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3> Part Three: Implement <code>cart</code> [Graded]</h3>\n",
    "\n",
    "In this section, you will implement the function <code>cart</code>, which returns a regression tree based on the minimum squared loss splitting rule. You should use the function <code>sqsplit</code> to make your splits. <p>Use the provided <code>TreeNode</code> class below to represent your tree. Note that the nature of CART trees implies that every node has exactly 0 or 2 children.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tree Structure</h4>\n",
       "\n",
       "<p>We've provided a tree structure for you with distinct leaves and nodes. Leaves have two fields, parent (another node) and prediction (a numerical value).</p>\n",
       "\n",
       "<strong>Nodes have six fields:</strong>\n",
       "\n",
       "<ol>\n",
       "<li> <b>left</b>: node describing left subtree </li>\n",
       "<li> <b>right</b>: node describing right subtree </li>\n",
       "<li> <b>feature</b>: index of feature to cut </li>\n",
       "<li> <b>cut</b>: cutoff value c (<=c : left, and >c : right)</li>\n",
       "<li> <b>prediction</b>: prediction at this node </li>. This should be the average of the labels at this node.\n",
       "</ol>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h4>Tree Structure</h4>\n",
    "\n",
    "<p>We've provided a tree structure for you with distinct leaves and nodes. Leaves have two fields, parent (another node) and prediction (a numerical value).</p>\n",
    "\n",
    "<strong>Nodes have six fields:</strong>\n",
    "\n",
    "<ol>\n",
    "<li> <b>left</b>: node describing left subtree </li>\n",
    "<li> <b>right</b>: node describing right subtree </li>\n",
    "<li> <b>feature</b>: index of feature to cut </li>\n",
    "<li> <b>cut</b>: cutoff value c (<=c : left, and >c : right)</li>\n",
    "<li> <b>prediction</b>: prediction at this node </li>. This should be the average of the labels at this node.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    \"\"\"Tree class.\n",
    "    (You don't need to add any methods or fields here but feel\n",
    "    free to if you like. The tests will only reference the fields\n",
    "    defined in the constructor below, so be sure to set these\n",
    "    correctly.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, left, right, feature, cut, prediction):\n",
    "        self.left = left \n",
    "        self.right = right \n",
    "        self.feature = feature \n",
    "        self.cut = cut\n",
    "        self.prediction = prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The following cell contains some examples of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is a tree that predicts everything as zero ==> prediction 0\n",
    "# In this case, it has no left or right children (it is a leaf node) ==> left = None, right = None\n",
    "# The tree also do not split at any feature at any value ==> feature = None, cut = None, \n",
    "root = TreeNode(None, None, None, None, 0)\n",
    "\n",
    "\n",
    "# The following that a tree with depth 2\n",
    "# or a tree with one split \n",
    "# The tree will return a prediction of 1 if an example falls under the left subtree\n",
    "# Otherwise it will return a prediction of 2\n",
    "# To start, first create two leaf node\n",
    "left_leaf = TreeNode(None, None, None, None, 1)\n",
    "right_leaf = TreeNode(None, None, None, None, 2)\n",
    "\n",
    "# Now create the parent or the root\n",
    "# Suppose we split at feature 0 and cut of 1\n",
    "# and the average prediction is 1.5\n",
    "root2 = TreeNode(left_leaf, right_leaf, 0, 1 , 1.5)\n",
    "\n",
    "# Now root2 is the tree we desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart(xTr,yTr):\n",
    "    \"\"\"Builds a CART tree.\n",
    "    \n",
    "    The maximum tree depth is defined by \"maxdepth\" (maxdepth=2 means one split).\n",
    "    Each example can be weighted with \"weights\".\n",
    "\n",
    "    Args:\n",
    "        xTr:      n x d matrix of data\n",
    "        yTr:      n-dimensional vector\n",
    "\n",
    "    Returns:\n",
    "        tree: root of decision tree\n",
    "    \"\"\"\n",
    "    n,d = xTr.shape\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #Can you split it?\n",
    "    #if yes leftnode = cart(leftxTr, leftyTr), rightnode = cart(rightx, right y)\n",
    "    \n",
    "    '''\n",
    "    new\n",
    "    '''\n",
    "    if (n < 2 ):\n",
    "        return TreeNode(None,None,None, None, np.mean(yTr))\n",
    "    \n",
    "    feature, cut, bestloss = sqsplit(xTr,yTr)\n",
    "    \n",
    "    if feature != np.inf:\n",
    "        #print('feature: ', feature)\n",
    "        #print('cut: ', cut)\n",
    "        #print('bestloss: ', bestloss)\n",
    "        #print('xxx: ', xTr[:,feature]<=cut)\n",
    "        #print('XXXTr: ', xTr[xTr[:,feature]<=cut])\n",
    "        #print('yyyy: ', yTr[xTr[:,feature]<=cut])\n",
    "        #xTrL = \n",
    "        #leftxTr = xTr[xTr[:,feature]<=cut]  -change\n",
    "        #rightxTr = xTr[xTr[:,feature]>=cut] -change\n",
    "        #print(\"xTr[:,feature]<=cut\",xTr[:,feature]<=cut)\n",
    "        #print(\"xTr[:,feature]<=cut----\",xTr[xTr[:,feature]<=cut])\n",
    "        leftxTr =  xTr[xTr[:,feature]<=cut]\n",
    "        rightxTr = xTr[xTr[:,feature]>cut] ## removed =\n",
    "        leftyTr = yTr[xTr[:,feature]<=cut]\n",
    "        #rightyTr = yTr[xTr[:,feature]>=cut] -change\n",
    "        rightyTr = yTr[xTr[:,feature]>cut]\n",
    "        leftTree = cart(leftxTr,leftyTr)\n",
    "        rightTree = cart(rightxTr,rightyTr)\n",
    "        prediction = np.mean(yTr)\n",
    "        #parentNode = TreeNode(leftTree, rightTree , feature, cut, prediction)-chnage\n",
    "        return TreeNode(leftTree, rightTree , feature, cut, prediction)\n",
    "    else:\n",
    "        prediction = np.mean(yTr)\n",
    "        #treeRoot = TreeNode(None,None,None, None, prediction)   # (leftTree, rightTree , feature, cut, predict)-change\n",
    "        return TreeNode(None,None,None, None, prediction)   # (leftTree, rightTree , feature, cut, predict)\n",
    "    \n",
    "    #print('Tree: ', treeRoot)\n",
    "    #print('predict', predict)\n",
    "    \n",
    "    #return treeNode\n",
    "    \n",
    "    #raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tests below check that your implementation of cart  returns the correct predicted values for a sample dataset\n",
    "\n",
    "#test case 1\n",
    "def cart_test1():\n",
    "    t=cart(xor4,yor4)\n",
    "    return DFSxor(t)\n",
    "\n",
    "#test case 2\n",
    "def cart_test2():\n",
    "    y = np.random.rand(16);\n",
    "    t = cart(xor4,y);\n",
    "    yTe = DFSpreds(t)[:];\n",
    "    # Check that every label appears exactly once in the tree\n",
    "    y.sort()\n",
    "    yTe.sort()\n",
    "    return np.all(np.isclose(y, yTe))\n",
    "\n",
    "#test case 3\n",
    "def cart_test3():\n",
    "    xRep = np.concatenate([xor2, xor2])\n",
    "    yRep = np.concatenate([yor2, 1-yor2])\n",
    "    t = cart(xRep, yRep)\n",
    "    return DFSxorUnsplittable(t)\n",
    "\n",
    "#test case 4\n",
    "def cart_test4():\n",
    "    X = np.ones((5, 2)) # Create a dataset with identical examples\n",
    "    y = np.ones(5)\n",
    "    \n",
    "    # On this dataset, your cart algorithm should return a single leaf\n",
    "    # node with prediction equal to 1\n",
    "    t = cart(X, y)\n",
    "    \n",
    "    # t has no children\n",
    "    children_check = (t.left is None) and (t.right is None) \n",
    "    \n",
    "    # Make sure t does not cut any feature and at any value\n",
    "    feature_check = (t.feature is None) and (t.cut is None)\n",
    "    \n",
    "    # Check t's prediction\n",
    "    prediction_check = np.isclose(t.prediction, 1)\n",
    "    return children_check and feature_check and prediction_check\n",
    "\n",
    "#test case 5\n",
    "def cart_test5():\n",
    "    X = np.arange(4).reshape(-1, 1)\n",
    "    y = np.array([0, 0, 1, 1])\n",
    "\n",
    "    t = cart(X, y) # your cart algorithm should generate one split\n",
    "    \n",
    "    # check whether you set t.feature and t.cut to something\n",
    "    return t.feature is not None and t.cut is not None\n",
    "\n",
    "\n",
    "\n",
    "runtest(cart_test1,'cart_test1')\n",
    "runtest(cart_test2,'cart_test2')\n",
    "runtest(cart_test3,'cart_test3')\n",
    "runtest(cart_test4,'cart_test4')\n",
    "runtest(cart_test5,'cart_test5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Part Four: Implement <code>evaltree</code> [Graded]</h3>\n",
       "\n",
       "<p>Implement the function <code>evaltree</code>, which evaluates a decision tree on a given test data set.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3> Part Four: Implement <code>evaltree</code> [Graded]</h3>\n",
    "\n",
    "<p>Implement the function <code>evaltree</code>, which evaluates a decision tree on a given test data set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaltree(root,xTe):\n",
    "    \"\"\"Evaluates xTe using decision tree root.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    pred = []\n",
    "    '''\n",
    "    for i in rsnge N\n",
    "        XTE[I]\n",
    "    root has a cut\n",
    "    while loop\n",
    "        xte  000110\n",
    "        cut  - 0.5\n",
    "        f= 2.\n",
    "        root .lrft = root\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    for i in range(N):\n",
    "        while root.cut !=None:\n",
    "            \n",
    "            if root.feature == None and root.cut == None:\n",
    "        pred.append(root.prediction)\n",
    "        return root.prediction\n",
    "    \n",
    "    if xTe[root.feature] <= root.cut:\n",
    "        evaltree(root.left, xTe)\n",
    "    if xTe[root.feature] > root.cut:\n",
    "        evaltree(root.right,xTe)\n",
    "    return pred\n",
    "\n",
    "\n",
    "#         if root.feature == None and root.cut == None:\n",
    "#         pred.append(root.prediction)\n",
    "#         return root.prediction\n",
    "    \n",
    "#     if xTe[root.feature] <= root.cut:\n",
    "#         evaltree(root.left, xTe)\n",
    "#     if xTe[root.feature] > root.cut:\n",
    "#         evaltree(root.right,xTe)\n",
    "#     return pred\n",
    "#         evaltree(root.left\n",
    "    \n",
    "#     while root.left:\n",
    "#         if xTr[:root.feature] <= root.cut:\n",
    "#             root = root.left\n",
    "#         else:\n",
    "#             root = root.right\n",
    "#     return root.prediction\n",
    "    \n",
    "#     if root.feature:\n",
    "#         left = evaltree(root.left,xTe[:, feature]<=root.cut)\n",
    "#         right = evaltree(root.right, xTe[:, feature]>root.cut)\n",
    "#         print('left: ', left)\n",
    "#         print('right: ', right)\n",
    "#         return left, right\n",
    "\n",
    "    #print('rootfeature: ', root.feature)\n",
    "    #print('rootleft: ', root ==True)\n",
    "    #print('rootcut: ', root.cut)\n",
    "    #print('rootpred: ', root.right.prediction)\n",
    "    print('xTe: ', xTe[0])\n",
    "    \n",
    "    pred = root.prediction\n",
    "    print('pred: ', pred)\n",
    "    \n",
    "    #return pred\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "a = TreeNode(None, None, None, None, 1)\n",
    "b = TreeNode(None, None, None, None, -1)\n",
    "c = TreeNode(None, None, None, None, 0)\n",
    "d = TreeNode(None, None, None, None, -1)\n",
    "e = TreeNode(None, None, None, None, -1)\n",
    "x = TreeNode(a, b, 0, 10, 0)\n",
    "y = TreeNode(x, c, 0, 20, 0)\n",
    "z = TreeNode(d, e, 0, 40, 0)\n",
    "t = TreeNode(y, z, 0, 30, 0)\n",
    "# Check that the custom tree evaluates correctly\n",
    "print(evaltree(t, np.array([[45, 35, 25, 15, 5]]).T),np.array([-1, -1, 0, -1, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following tests check that your implementation of evaltree returns the correct predictions for two sample trees\n",
    "\n",
    "t0 = time.time()\n",
    "root = cart(xTrIon, yTrIon)\n",
    "t1 = time.time()\n",
    "\n",
    "tr_err   = np.mean((evaltree(root,xTrIon) - yTrIon)**2)\n",
    "te_err   = np.mean((evaltree(root,xTeIon) - yTeIon)**2)\n",
    "\n",
    "print(\"Elapsed time: %.2f seconds\" % (t1-t0))\n",
    "print(\"Training RMSE : %.2f\" % tr_err)\n",
    "print(\"Testing  RMSE : %.2f \\n\" % te_err)\n",
    "\n",
    "#test case 1\n",
    "def evaltree_test1():\n",
    "    t = cart(xor4,yor4)\n",
    "    xor4te = xor4 + (np.sign(xor4 - .5) * .1)\n",
    "    inds = np.arange(16)\n",
    "    np.random.shuffle(inds)\n",
    "    # Check that shuffling and expanding the data doesn't affect the predictions\n",
    "    return np.all(np.isclose(evaltree(t, xor4te[inds,:]), yor4[inds]))\n",
    "\n",
    "#test case 2\n",
    "def evaltree_test2():\n",
    "    a = TreeNode(None, None, None, None, 1)\n",
    "    b = TreeNode(None, None, None, None, -1)\n",
    "    c = TreeNode(None, None, None, None, 0)\n",
    "    d = TreeNode(None, None, None, None, -1)\n",
    "    e = TreeNode(None, None, None, None, -1)\n",
    "    x = TreeNode(a, b, 0, 10, 0)\n",
    "    y = TreeNode(x, c, 0, 20, 0)\n",
    "    z = TreeNode(d, e, 0, 40, 0)\n",
    "    t = TreeNode(y, z, 0, 30, 0)\n",
    "    # Check that the custom tree evaluates correctly\n",
    "    return np.all(np.isclose(\n",
    "            evaltree(t, np.array([[45, 35, 25, 15, 5]]).T),\n",
    "            np.array([-1, -1, 0, -1, 1])))\n",
    "\n",
    "runtest(evaltree_test1,'evaltree_test1')\n",
    "runtest(evaltree_test2,'evaltree_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Visualize Your Tree</h3>\n",
       "\n",
       "<p>The following code defines a function <code>visclassifier()</code>, which plots the decision boundary of a classifier in 2 dimensions. Execute the following code to see what the decision boundary of your tree looks like on the ion data set. </p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3> Visualize Your Tree</h3>\n",
    "\n",
    "<p>The following code defines a function <code>visclassifier()</code>, which plots the decision boundary of a classifier in 2 dimensions. Execute the following code to see what the decision boundary of your tree looks like on the ion data set. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visclassifier(fun,xTr,yTr,w=None,b=0):\n",
    "    \"\"\"\n",
    "    visualize decision boundary\n",
    "    Define the symbols and colors we'll use in the plots later\n",
    "    \"\"\"\n",
    "\n",
    "    yTr = np.array(yTr).flatten()\n",
    "    \n",
    "\n",
    "    symbols = [\"ko\",\"kx\"]\n",
    "    marker_symbols = ['o', 'x']\n",
    "    mycolors = [[0.5, 0.5, 1], [1, 0.5, 0.5]]\n",
    "    # get the unique values from labels array\n",
    "    classvals = np.unique(yTr)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # return 300 evenly spaced numbers over this interval\n",
    "    res=300\n",
    "    xrange = np.linspace(min(xTr[:, 0]), max(xTr[:, 0]),res)\n",
    "    yrange = np.linspace(min(xTr[:, 1]), max(xTr[:, 1]),res)\n",
    "    \n",
    "    # repeat this matrix 300 times for both axes\n",
    "    pixelX = repmat(xrange, res, 1)\n",
    "    pixelY = repmat(yrange, res, 1).T\n",
    "\n",
    "    \n",
    "    xTe = np.array([pixelX.flatten(), pixelY.flatten()]).T\n",
    "\n",
    "    # test all of these points on the grid\n",
    "    testpreds = fun(xTe)\n",
    "    \n",
    "    # reshape it back together to make our grid\n",
    "    Z = testpreds.reshape(res, res)\n",
    "    # Z[0,0] = 1 # optional: scale the colors correctly\n",
    "    \n",
    "    # fill in the contours for these predictions\n",
    "    plt.contourf(pixelX, pixelY, np.sign(Z), colors=mycolors)\n",
    "\n",
    "    # creates x's and o's for training set\n",
    "    for idx, c in enumerate(classvals):\n",
    "        plt.scatter(xTr[yTr == c,0],\n",
    "            xTr[yTr == c,1],\n",
    "            marker=marker_symbols[idx],\n",
    "            color='k'\n",
    "            )\n",
    "    \n",
    "    if w is not None:\n",
    "        w = np.array(w).flatten()\n",
    "        alpha = -1 * b / (w ** 2).sum()\n",
    "        plt.quiver(w[0] * alpha, w[1] * alpha,\n",
    "            w[0], w[1], linewidth=2, color=[0,1,0])\n",
    "\n",
    "    plt.axis('tight')\n",
    "    # shows figure and blocks\n",
    "    plt.show()\n",
    "\n",
    "tree=cart(xTrSpiral,yTrSpiral) # compute tree on training data \n",
    "visclassifier(lambda X:evaltree(tree,X), xTrSpiral, yTrSpiral)\n",
    "print(\"Training error: %.4f\" % np.mean(np.sign(evaltree(tree,xTrSpiral)) != yTrSpiral))\n",
    "print(\"Testing error:  %.4f\" % np.mean(np.sign(evaltree(tree,xTeSpiral)) != yTeSpiral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick_cart(event):\n",
    "    \"\"\"\n",
    "    Visualize cart, including new point\n",
    "    \"\"\"\n",
    "    global xTraining,labels\n",
    "    # create position vector for new point\n",
    "    pos=np.array([[event.xdata,event.ydata]]) \n",
    "    if event.key == 'shift': # add positive point\n",
    "        color='or'\n",
    "        label=1\n",
    "    else: # add negative point\n",
    "        color='ob'\n",
    "        label=-1    \n",
    "    xTraining = np.concatenate((xTraining,pos), axis = 0)\n",
    "    labels.append(label);\n",
    "    marker_symbols = ['o', 'x']\n",
    "    classvals = np.unique(labels)\n",
    "        \n",
    "    mycolors = [[0.5, 0.5, 1], [1, 0.5, 0.5]]\n",
    "    \n",
    "    # return 300 evenly spaced numbers over this interval\n",
    "    res=300\n",
    "    xrange = np.linspace(0, 1,res)\n",
    "    yrange = np.linspace(0, 1,res)\n",
    "\n",
    "    \n",
    "    # repeat this matrix 300 times for both axes\n",
    "    pixelX = repmat(xrange, res, 1)\n",
    "    pixelY = repmat(yrange, res, 1).T\n",
    "\n",
    "    xTe = np.array([pixelX.flatten(), pixelY.flatten()]).T\n",
    "\n",
    "    # get decision tree\n",
    "    tree=cart(xTraining,np.array(labels).flatten())\n",
    "    fun = lambda X:evaltree(tree,X)\n",
    "    # test all of these points on the grid\n",
    "    testpreds = fun(xTe)\n",
    "    \n",
    "    # reshape it back together to make our grid\n",
    "    Z = testpreds.reshape(res, res)\n",
    "    # Z[0,0] = 1 # optional: scale the colors correctly\n",
    "    \n",
    "    plt.cla()    \n",
    "    plt.xlim((0,1))\n",
    "    plt.ylim((0,1))\n",
    "    # fill in the contours for these predictions\n",
    "    plt.contourf(pixelX, pixelY, np.sign(Z), colors=mycolors)\n",
    "    \n",
    "    for idx, c in enumerate(classvals):\n",
    "        plt.scatter(xTraining[labels == c,0],\n",
    "            xTraining[labels == c,1],\n",
    "            marker=marker_symbols[idx],\n",
    "            color='k'\n",
    "            )\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "xTraining= np.array([[5,6]])\n",
    "labels = [1]\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick_cart)\n",
    "plt.title('Click to add positive points and use shift-click to add negative points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
